# Modelfile for CCF-ZKCS KV-Cache Proxy
#
# This creates an Ollama model that intercepts KV-cache writes
# and integrates with the CCF-ZKCS cache manager.
#
# Usage:
#   ollama create suhlabs/ccf_zkcs_proxy:latest -f Modelfile
#   ollama run suhlabs/ccf_zkcs_proxy:latest

FROM llama2:7b

# System prompt configuring cache-aware behavior
SYSTEM """You are an AI assistant running with CCF-ZKCS (Cryptographic Context Fingerprinting for Zero-Copy KV-Cache Sharing).

Your responses are optimized through intelligent KV-cache sharing across requests. This system:
- Deduplicates computation for similar contexts
- Reduces inference latency by 40-65%
- Maintains 100% deterministic outputs

All operations are zero-cloud and self-hosted with mTLS security.
"""

# Model parameters optimized for cache efficiency
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40

# Cache-friendly context window (aligned with CCF-ZKCS MAX_TOKENS_PER_REQUEST)
PARAMETER num_ctx 32768

# Enable KV-cache (critical for CCF-ZKCS)
PARAMETER use_mlock true
PARAMETER use_mmap true

# Template for structured prompts
TEMPLATE """{{ if .System }}<|system|>
{{ .System }}<|end|>
{{ end }}{{ if .Prompt }}<|user|>
{{ .Prompt }}<|end|>
{{ end }}<|assistant|>
{{ .Response }}<|end|>
"""

# License and attribution
LICENSE """
Apache 2.0 - SuhLabs ML Features
"""
